\documentclass[a4j,12pt]{jreport}
\usepackage[dvipdfmx]{graphicx}
\usepackage{float}
\usepackage{url} 
%\usepackage{slashbox}
%\usepackage{subfigure}
\newcommand{\ta}[1]{\texttt{#1}}
\usepackage{bm}
\usepackage{amsmath}

\title{\normalsize \underline{令和7年度 東京理科大学 卒業論文}\\
\vspace{3.0cm}
\LARGE{時系列のPOSデータに対する\\予測モデルの精度向上方法の提案}\\
\vspace{0.5em}
\normalsize{}
\vspace{0.5em}
}
\author{東京理科大学 創域理工学部 情報計算科学科 \\ 松澤研究室 4年\\6322011 太田葉音}
\date{\vspace{2.0em}
\underline{指導教員}\\
松澤智史
}

\begin{document}
\maketitle
\pagenumbering{roman}
\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage
\pagenumbering{arabic}
\newpage

\chapter{はじめに}
\section{研究背景}
近年、小売業や飲食業をはじめとする多様な産業において、レジでの商品スキャンや会計処理の過程で取得される販売時点情報管理データ（POS：Point of Sale）およびそれを拡張したID-POSデータを利用して需要予測を行うことが注目されている。
経済産業省の委託事業報告書では、ID-POSを活用した需要予測により小売業の発注精度を向上させる実証実験が行われており、発注精度の向上を通じてサプライチェーンの効率化や過剰在庫・食品ロスの削減につなげることが検討されている\footnote{\url{https://www.meti.go.jp/meti_lib/report/2023FY/000108.pdf}（参照 2025-12-5）}。
こうした流れのなかで、小売・流通分野の需要予測においては、大量の特徴量を扱え、高い予測精度と計算効率を兼ね備える機械学習手法の1つであるLightGBM\cite{ke2017lightgbm}が広く利用されている。

POSデータは店舗、商品カテゴリ、曜日、季節、販促施策など多様な要因が複雑に関係する構造を持つため、従来の単一モデルだけではこうした構造を十分に捉えきれず、予測精度のさらなる向上余地が残されている。
このような課題に対するアプローチの1つとして、近年さまざまな分野で、ベースモデルを事前に学習し、その上に追加的な学習を行うファインチューニング手法が用いられている。
ファインチューニングは一般に、新規データ到着時に既存モデルを再利用しつつ性能を向上させる再学習手法として利用されてきた。
一方で、POSデータのようにカテゴリ間で売上規模や変動特性が大きく異なるデータセットに対しては、POS全体で学習したベースモデルが捉えた共通パターンを保持したままカテゴリごとのファインチューニングを行うことで、予測精度の向上が期待される。


\section{研究の目的}
POSデータに対してLightGBMモデルにファインチューニングを施すことで、予測精度の改善が得られるかを検証する。複数の公開データセットを対象に、通常学習、Time Cross Validation、そして提案手法を比較し、ファインチューニングがPOSデータに対する精度向上の一手法として有効に機能することを明らかにする。
% ==================================================
\section{本論文の構成}
\noindent
2 章では基礎知識について述べる。\\
3 章では関連研究について述べる。\\
4 章では提案手法について述べる。\\
5 章では実験内容について述べる。\\
6 章では実験結果に関する評価および考察について述べる。\\
7 章では本論文のまとめについて述べる。\\

% ==================================================




    
\section{データについて}
本研究では以下のデータセットを用いる。
\begin{enumerate}
    \item Walmart Sales%
    \footnote{\url{https://www.kaggle.com/datasets/mikhail1681/walmart-sales} \\ (参照 2025-12-5)}

    \item Restaurant Sales Report%
    \footnote{\url{https://www.kaggle.com/datasets/rajatsurana979/fast-food-sales-report}\\(参照 2025-12-5)}
    
    \item Sales of a Supermarket%
    \footnote{\url{https://www.kaggle.com/datasets/lovishbansal123/sales-of-a-supermarket}\\(参照 2025-12-5)}
    
    \item {Store Sales Time Series Forecasting%
    \footnote{\url{https://www.kaggle.com/competitions/store-sales-time-series-forecasting}\\(参照 2025-12-5)}}

\end{enumerate}


% ==================================================
\chapter{基礎知識}
\section{決定木}
決定木は、入力される特徴量に対して、特定の特徴量があるしきい値以上かどうかなどの条件に基づいてデータを順に分割していき、最終的に葉ノードと呼ばれる末端のノードごとに予測値（回帰問題であれば数値、分類問題であればクラス）が割り当てられるモデルである。根ノードから葉ノードまでの分岐は、人間が理解しやすいif--thenルールの列として表現できるため、予測結果の解釈が比較的容易である。また、特徴量のスケーリングを必要とせず、非線形な関係や特徴量同士の相互作用も表現しやすいという利点がある。

\section{LightGBM}
LightGBMは、決定木を多数逐次的に学習し、それぞれが前のモデルの誤差を補正するように重ね合わせることで、最終的な予測性能を高める勾配ブースティング決定木の一実装である。その中でも、特に高速な学習とメモリ効率の良さ、大規模データセットへの適用のしやすさを重視して設計されている。


\section{Early Stopping}

勾配ブースティングやニューラルネットワークなどの反復学習型アルゴリズムにおいては、
学習回数を増やしすぎると訓練データに過度に適合し、
未知データに対する汎化性能が低下する過学習が生じることがある。
この問題に対処する手法の1つがEarly Stoppingである。

Early Stoppingでは、訓練データとは別に検証データを用意し、
各イテレーションにおける検証データに対する評価指標を監視する。
検証誤差が一定回数分のイテレーションにわたって改善しなくなった時点で
学習を終了し、その時点までで最も性能の良かったモデルを採用する。
これにより、以下のような利点が得られる。

\begin{itemize}
  \item 過学習が始まる前のタイミングで学習を停止できるため、汎化性能の低下を抑制できる
  \item 学習回数を自動的に調整できるため、不要なイテレーションを避け、計算時間を削減できる
  \item ハイパーパラメータとして学習回数を過度に大きく設定しても、
        Early Stoppingによって実際の有効な学習回数が自動的に制御される
\end{itemize}



\section{Time Cross Validation}

時系列データを対象とする予測モデルの評価では、データの時系列順序を保存したまま
訓練データと検証データを分割する必要がある。
一般的な$k$-foldクロスバリデーションでは、データの時系列を考慮せずに任意に分割するため、
検証データよりも将来のデータを学習した状態で評価してしまう。
この問題は時系列予測において重大であり、モデルが過大評価される原因となる。

この問題を避けるために用いられる手法が
Time Cross Validationである。
時系列順序を維持したまま、
過去から未来へ向かう形で訓練期間と検証期間を複数設定し、
それぞれの分割に対してモデルを学習および評価する（図\ref{drow}）。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{drow.png}
\caption{Time Cross Validationの分割例}
\label{drow}
\end{figure}

Time Cross Validationの一般的な分割方法は以下のとおりである。

\begin{itemize}
  \item 分割1：過去のデータを訓練、直後の一定期間を検証に使用する
  \item 分割2：訓練期間を前方へ広げ、次の期間を検証に使用する
  \item 分割1と分割2を複数回繰り返し、各分割の評価指標の平均を最終的なモデル指標とする
\end{itemize}


\section{MAE (平均絶対誤差)}

回帰タスクにおけるモデルの評価指標の1つである。

観測値を$y_i$、モデルによる予測値を$\hat{y}_i$、
サンプル数を$N$とすると、MAEは式(\ref{eq:mae})で定義される。

\begin{equation}
  MAE = \frac{1}{N} \sum_{i=1}^{N} \left| y_i - \hat{y}_i \right|
  \label{eq:mae}
\end{equation}

MAEは各サンプルにおける誤差の絶対値を平均したものであり、
以下のような特徴をもつ。

\begin{itemize}
  \item 誤差の単位が目的変数と同じであるため、解釈が直感的である
  \item 二乗誤差を用いる指標（MSE、RMSE）に比べて外れ値の影響を受けにくい
  \item 正負の誤差が打ち消し合うことがないため、全体としてのずれの大きさを素直に反映する
  \item MAEの値が小さいほど誤差が小さい、すなわち精度がよいと解釈する
\end{itemize}


\chapter{関連研究}
\section{ファインチューニング}
ファインチューニングは、事前学習によって獲得した汎用的な表現を基礎とし、
目的とするタスクやデータに合わせてモデルを追加学習する手法である。
Hintonら\cite{hinton2006_dbn_finetune}は、
深層生成モデルに対して教師なし事前学習と教師あり微調整を組み合わせた
二段階学習アルゴリズムを提案し、この枠組みを明確に示した。

\section{LightGBMでファインチューニングを行う例}
Yeら\cite{ye2023_pv_finetune}は、太陽光発電プラントにおける出力予測を対象として、
LightGBMと、勾配ブースティング決定木に基づく機械学習手法であるXGBoostを組み合わせた予測モデルを提案している。
具体的には、まず複数プラントから得られた気象データを用いて大規模な学習データセットを構成し、
LightGBMおよびXGBoostによるハイブリッドモデルを事前学習する。
その後、新たな発電所や環境条件に対応するために、各プラント固有のデータに対して
ファインチューニングを行うことで、出力予測精度と汎化性能の向上を図っている。
実験の結果、提案モデルは従来手法と比較して、
複数地点を同時に予測する設定において一貫して低い誤差を達成した。

\section{本研究の位置づけ}
Yeらの手法が、既存データで学習したモデルを新しいデータへ適応させるためにファインチューニングを用いるのに対し、本研究では既存データへの性能を高める目的で、既存データを分割してファインチューニングを行う。


% ========================================================================================
\chapter{提案手法}
\section{提案手法の内容}
本研究では、LightGBMによって学習したベースモデルに対し、カテゴリカルカラムごとにファインチューニングを行うことで予測精度を向上させる。手順を以下に示す。

\begin{enumerate}
  \item ベースモデルの学習

  \quad 全データを用いてLightGBMのモデルを学習し、全体的な傾向を捉えたベースモデルを構築する。

  \item データのカテゴリ別分割

  \quad カテゴリカルカラムを1つ選択する。選択したカテゴリカルカラムの値ごとにデータを分割し、カテゴリごとの部分データセットを作成する。

  \item ベースモデルの重みを初期値としたファインチューニング

  \quad 各カテゴリのデータセットに対して、ベースモデルの重みを初期値として当該カテゴリに属するデータのみでファインチューニングを行う。これにより、ベースモデルが保持する全体傾向を維持したまま、カテゴリ特有の挙動をモデルに反映させることができる。

  \item 推論時のモデル選択

  \quad 推論時には、入力データが属するカテゴリに対応するファインチューニング済みモデルを選択し、そのモデルを用いて予測値を算出する。
\end{enumerate}


データセットにカテゴリカルカラムcol\_catが存在し、A、Bのどちらかの値であるときの提案手法の例を示す(図\ref{model-ex})。

\begin{figure}[H]
\centering 
\includegraphics[scale=0.5]{model-ex.png}
\caption{提案手法の処理を表すフロー}
\label{model-ex}
\end{figure}

\section{提案手法の位置づけ}
本手法が位置付けられる領域は、初期モデル学習後の精度改善手法であり、クロスバリデーションと同じ段階に属する。

本研究の提案手法は、ベースモデルが捉える大域的な傾向を保持しつつ、
カテゴリ単位の局所的な挙動を補正する点に特徴をもつ。
したがって、本手法はLightGBMを用いた予測タスクにおける
仕上げの精度改善手法として位置付けられる。
本研究では時系列版のクロスバリデーションを比較対象とする。
% ================================================================
\chapter{実験内容}
\section{使用するデータセット}

本研究では、LightGBMを用いた予測タスクの汎用性を確認するため、
構造や規模の異なる4種類の公開データセットを用いる。
いずれも売上または販売数量を目的変数とする時系列データである。

\subsection{Walmart Sales}

Walmartにおける週次売上データであり、各店舗・各部門の売上推移を扱う。
本研究では、以下の主要特徴量を使用する。

\begin{itemize}
  \item Store：店舗IDを表すカテゴリカルカラム
  \item Date：週次データの日付
  \item Weekly\_Sales：該当週の売上金額（目的変数）
  \item Holiday\_Flag：祝日週か否かを示すフラグ
  \item Temperature：その週の平均気温
  \item Fuel\_Price：燃料価格
  \item CPI：消費者物価指数
  \item Unemployment：失業率
\end{itemize}

これらの特徴量は、天候・価格・経済指標などが売上に影響を与える点を捉えるために適している。

\subsection{Restaurant Sales Report}

ローカルレストランにおける日次販売記録であり、以下のカテゴリカルカラムと
数値変数を含む。

\begin{itemize}
  \item Date：日付
  \item Item\_Name：商品名を表すカテゴリカルカラム
  \item Item\_Type：食品または飲料などの商品カテゴリ
  \item Item\_Price：商品の単価
  \item Quantity：販売数量（目的変数）
  \item Transaction\_Type：現金・オンラインなどの支払い方法
  \item Received\_By：担当したスタッフの性別
  \item Time\_of\_Sale：販売時間帯（Morning、Afternoon など）
\end{itemize}

複数のカテゴリカルカラムを含むため、LightGBMのカテゴリカル処理性能が評価しやすいデータセットである。

\subsection{Sales of a Supermarket}

スーパーマーケットの販売記録であり、個々の取引情報を含む。
使用する主な特徴量は以下のとおりである。

\begin{itemize}
  \item Branch：店舗（A、B、C）の識別子
  \item Customer\_Type：会員・非会員などの顧客タイプ
  \item Gender：顧客の性別
  \item Product\_Line：商品カテゴリ
  \item Unit\_Price：商品の単価
  \item Quantity：販売数量（目的変数）
  \item Date：購入日
  \item Time：購入時刻
  \item Payment：支払い方法
  \item Rating：顧客満足度を表す 1〜10 のスコア
\end{itemize}

カテゴリカルカラムと数値変数の両方を多く含む点が特徴である。

\subsection{Store Sales Time Series Forecasting}

Ecuador の大手スーパーマーケットチェーンにおける大規模販売データであり、
店舗・商品ファミリー別の日次販売数を扱う。

\begin{itemize}
  \item Date：日付
  \item Store\_Nbr：店舗番号
  \item Family：製品ファミリー（カテゴリカルカラム）
  \item Sales：販売数量（目的変数）
  \item OnPromotion：プロモーション対象商品数
\end{itemize}



\section{実験手順}

各データセットに対してLightGBMを用いた3種類の手法でモデルを構築し、
予測性能を比較する。
また、提案手法におけるファインチューニングの影響を適切に評価するため、学
習には Early Stoppingを導入する。

\begin{enumerate}
  \item \textbf{ベースライン（単一LightGBMモデル）}

  \quad 全データセットを訓練データとして用いてLightGBMを学習する。

  \item \textbf{Time Cross Validation}

  \quad 時系列の順序を保持したまま複数の訓練期間と評価期間を設定し、
  各分割ごとにLightGBMを学習する。
  各分割の誤差の平均値を評価指標として用いる。

  \item \textbf{提案手法（カテゴリ別ファインチューニング）}

  \quad まず、全データを用いてLightGBMのベースモデルを構築する。
  次に、データセットに含まれるカテゴリカルカラムのうち、
  種類数が最も多いカラムを1つ選択し、その値ごとにデータセットを分割する。
  各カテゴリに対して、ベースモデルの重みを初期値として読み込み、
  当該カテゴリのデータのみを用いてファインチューニングを行う。
  
  \quad さらに、提案手法の安定性を検証するため、
  目的変数と無関係に乱数で生成したカテゴリカルカラム
  （A、B、Cの3値をランダムに付与したもの）を1列だけ追加した条件でも実験を行う。
  この際、元の特徴量および目的変数には一切変更を加えない。
  ランダムカラムをカテゴリ分割の基準として用いてファインチューニングを行い、
  精度の変化を観察する。
  これは、無意味なカテゴリに対して過適合することなく、
  ベースモデルが保持する大域的傾向が精度を損なわないことを確認するためである。
  推論時には、入力サンプルが属するカテゴリに対応した
  ファインチューニング済みモデルを選択し、予測値を算出する。
\end{enumerate}
各データセットにおいて、検証データの期間は表\ref{val-periods}のように設定する。

\begin{table}[H]
\centering
\caption{各データセットにおける検証データ期間}
\label{val-periods}
\begin{tabular}{lccc}
\hline
\textbf{Dataset} & \textbf{データ開始日} & \textbf{検証開始日} & \textbf{検証終了日} \\
\hline
Walmart Sales & 2010-02-05 & 2012-09-01 & 2012-09-30 \\
Restaurant Sales Report & 2022-01-04 & 2023-10-01 & 2023-10-31 \\
Sales of a Supermarket & 2019-01-01 & 2019-02-01 & 2019-02-28 \\
Store Sales Time Series Forecasting & 2013-01-01 & 2017-07-01 & 2017-07-31 \\
\hline
\end{tabular}
\end{table}


\section{LightGBMのパラメータ}

本研究で用いるLightGBMのパラメータは以下である。

\begin{itemize}
  \item 決定木の最大本数：5000
  \item 木の最大深さ：20
  \item 学習率：0.01
  \item 分割の最小利得：0.1
  \item 目的関数：regression
\end{itemize}

\section{Time Cross Validationにおけるデータの分割方法}
まず表\ref{val-periods}に示した検証期間を固定し、その期間より前の全データを訓練データ候補とする。すなわち、検証期間は常に時系列の末尾側に配置され、訓練データはその直前までの履歴データのみから構成される。

訓練データ候補に対しては、日付を表す列を用いて昇順にソートしたうえで、Time Cross Validationの各分割を構成する。ここで、全訓練サンプル数を$N$とし、$k$番目の分割（$k=1,\dots,10$）における訓練データサイズ$N_k$を、式\ref{eq:tcv_split}のように定める。

\begin{equation}
  N_k = \left\lceil \frac{k}{10} N \right\rceil
  \label{eq:tcv_split}
\end{equation}

訓練データのうち先頭から$N_k$件を用いてモデルを学習し、表\ref{val-periods}で定めた検証期間のデータを検証データとして評価する。

\section{評価指標}
POSデータにおける売上金額や販売数量の予測では、
「平均してどれくらい外しているか」をそのままの単位で把握できることが重要である。
そのため、本研究では、売上や数量のような非負の連続値を対象とする
予測タスクに適した指標としてMAEを採用し、各手法の性能比較に用いる。
% ================================================================

\chapter{実験結果と考察}
\section{実験結果}
各データセットに対するそれぞれの手法のMAEを示す（表\ref{mae-main}）。
\begin{table}[H]
\centering
\caption{各データセットにおける手法ごとのMAE}
\label{mae-main}
\begin{tabular}{c|rrr}
\hline
データセット & ベースライン & Time Cross Validation & 提案手法 \\
\hline
Walmart Sales & 66480.5938 & 82751.7063 & 52892.0512 \\
Restaurant Sales Report & 1.4848 & 1.4971 & 1.3311 \\
Sales of a Supermarket & 2.6108 & 2.6312 & 2.5982 \\
Store Sales Time Series Forecasting & 116.5991 & 152.5574 & 113.7269 \\
\hline
\end{tabular}
\end{table}

全てのデータセットにおいて、提案手法の MAE は、ベースライン、Time Cross Validationより小さくなっている。


次に、ランダムカラム追加時の実験結果を表\ref{mae-random-change}に示す。

\begin{table}[H]
\centering
\caption{ベースラインに対するランダムカラム追加時の MAE}
\label{mae-random-change}
\begin{tabular}{c|rr}
\hline
データセット & ベースライン & ランダムなカラム \\
\hline
Walmart Sales & 66480.5938 & 65435.7049 \\
Restaurant Sales Report & 1.4848 & 1.3545  \\
Sales of a Supermarket & 2.6108 & 2.6001  \\
Store Sales Time Series Forecasting & 116.5991 & 115.4678 \\
\hline
\end{tabular}
\end{table}



\section{考察}
\subsection{精度の改善について}
4 つのデータセット全てにおいて、
提案手法の MAE はベースラインおよびTime Cross Validationよりも小さい値を示した。

POSデータでは、店舗や商品カテゴリごとに売上の水準や変動幅が大きく異なる。
ベースラインでは、全体のデータを1つのモデルで学習するため、
データ数の多い店舗や商品カテゴリに引きずられやすく、
一部のカテゴリに対してはバイアスの大きい予測となる可能性がある。
これに対して提案手法では、ベースモデルで大域的な季節性やトレンドを学習したあと、
カテゴリごとのデータのみを用いてファインチューニングを行うことで、
各カテゴリに固有の水準や変動パターンを反映できる。
その結果として、特にカテゴリ間の差異が大きい
Walmart SalesやStore Sales Time Series Forecastingにおいて、
ベースラインと比べて顕著なMAEの改善が見られた。

また、Time Cross Validationは時系列の順序を保った評価方法であり、汎化性能を厳密に測るうえで有用である。一方、各分割で利用可能な訓練データは限定される。
したがって、十分なデータ量を用いて学習できるベースラインや提案手法と比べると、
モデルが学習できる情報量が少なく、MAEが大きくなる傾向が表れた。

さらに、
目的変数と無関係なランダムカラムを追加し、
そのカラムに基づいてカテゴリ別ファインチューニングを行った場合でも、
MAEは常に小さくなる。
ランダムカラムによる分割では、学習データが複数の部分集合に分割されることで、
部分集合ごとにモデルがより限定されたデータ分布に適応する余地が生じる。その結果、検証データに対する誤差の縮小余地が生まれ、
ランダムなカラムであってもベースラインよりMAEはわずかに改善した。
このように目的変数と無関係なカラムでも性能が悪化しないことは、手法自体が過度に過学習しにくく、安定して適用できることを示している。


以上より、提案手法が精度向上を達成した主な要因は、
\begin{enumerate}
    \item ベースモデルによる大域的傾向の獲得
    \item カテゴリ別ファインチューニングによる局所的挙動の補正
\end{enumerate}
の2つがうまく分担している点にある。
この二段階構成により、POSデータのように
「全体としては共通のパターンをもちつつ、カテゴリごとに挙動が異なる」
という構造をもつデータに対して、有効に機能する手法である。

% ===================================

\subsection{カテゴリカルカラムの選択方法について}
本研究では、単に種類数が最も多いカラムを機械的に選択した。しかし、扱うデータセットによっては他のカラムを選択した方がよい場合も存在する。以下に、選択基準となりうる要素を述べる。
\begin{enumerate}
    \item 種類数が多いカラムを選択した方がよい。ただし、多すぎるカラムは選ぶべきではない。例えば、ID に相当するカラムを選択すると、1 つのデータのみでファインチューニングを行うことになり、精度の改善は望めない。
    \item 各分割間で分布や傾向が十分に異なるようなカラムを選択することが望ましい。例えば、「性別、学年、身長」からなる小学生のデータセットが存在し、身長を目的変数とするタスクを考える。このとき、カテゴリカルカラムとして性別と学年のいずれを用いることもできるが、学年ごとにデータを分割した方が、各学年で身長の水準や分布が大きく異なるため、より明確に傾向の異なる分割を得ることができる。
\end{enumerate}


\chapter{おわりに}
本研究では、LightGBMによるベースモデル学習に対して、
カテゴリ別ファインチューニングを組み合わせた精度向上手法を提案し、
複数の公開データセットを用いてその有効性を検証した。
実験の結果、提案手法はベースラインおよび
Time Cross Validationと比較して一貫して
低いMAEを示し、予測精度を向上させることが確認できた。
また、無関係なランダムカテゴリを追加した条件でも精度が大きく崩れず、
手法の安定性が示された。
本研究で得られた結果は、POSデータのように
カテゴリごとに異なるパターンを含む時系列データに対して、
ベースモデルとファインチューニングを組み合わせるアプローチが有効であることを示した。

%===============================================================
\chapter*{謝辞}
本研究を進めるにあたり、松澤智史准教授には終始ご指導と温かい励ましをいただきました。深く感謝申し上げます。また、電気電子情報工学科の鈴木海友助教には、研究の進め方や技術的な助言を賜り、心より御礼申し上げます。さらに、松澤研究室の皆様には、日々の議論や助言を通して本研究に多くの示唆をいただきました。この場を借りて厚く感謝いたします。

\newpage
\renewcommand{\bibname}{参考文献}
\bibliographystyle{junsrt}
\bibliography{refs}     


\end{document}