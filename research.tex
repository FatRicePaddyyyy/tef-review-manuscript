\documentclass[a4j,12pt]{jreport}
\usepackage[dvipdfmx]{graphicx}
\usepackage{float}
\usepackage{url} 
%\usepackage{slashbox}
%\usepackage{subfigure}
\newcommand{\ta}[1]{\texttt{#1}}
\usepackage{bm}
\usepackage{amsmath}

\title{\normalsize \underline{令和7年度 東京理科大学 卒業論文}\\
\vspace{3.0cm}
\LARGE{時系列のPOSデータに対する\\予測モデルの精度向上方法の提案}\\
\vspace{0.5em}
\normalsize{}
\vspace{0.5em}
}
\author{東京理科大学 創域理工学部 情報計算科学科 \\ 松澤研究室 4年\\6322011 太田葉音}
\date{\vspace{2.0em}
\underline{指導教員}\\
松澤智史
}

\begin{document}
\maketitle
\pagenumbering{roman}
\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage
\pagenumbering{arabic}
\newpage

\chapter{はじめに}
\section{研究背景}
近年、小売業や飲食業をはじめとする多様な産業で、
POS（Point of Sale）およびそれに拡張されたID-POSデータにもとづく需要予測に注目が集まっている。
経済産業省の委託事業報告書では、ID-POSを活用した需要予測により
小売業の発注精度を向上させる実証実験が行われており、
発注精度の向上を通じてサプライチェーンの効率化や
過剰在庫・食品ロスの削減につなげることが検討されている\footnote{\url{https://www.meti.go.jp/meti_lib/report/2023FY/000108.pdf}}。
こうした流れのなかで、高い予測精度と計算効率を兼ね備える機械学習手法の1つである
LightGBM\cite{ke2017lightgbm}が広く利用されている。




LightGBMはPOSデータに対しても適用可能であり、より精度を高めるための追加的な工夫が依然として求められている。POSデータは店舗・商品カテゴリ・曜日・季節性など、多様な要因が複雑に関係する構造を持つため、既存の学習手法に対する後押しとして精度向上の余地が残されている。

そのような背景のもと、本研究ではLightGBMによるベースモデルを作成し、追加的な学習を施すファインチューニングに着目する。ファインチューニングは一般に新規データ到着時の再学習手法として用いられることが多い。POSデータのようにカテゴリ間で売上の規模や変動特性が異なるデータセットにおいて、初期モデルの知識を活かしつつ再学習を行うことで予測精度が向上する可能性がある。

\section{研究の目的}
POSデータに対してLightGBMモデルに追加学習を施すことで、予測精度の改善が得られるかを検証する。複数の公開データセットを対象に、通常学習、時系列クロスバリデーション、そして提案手法を比較し、ファインチューニングが精度向上の一手法として有効に機能することを明らかにする。
% ==================================================
\section{本論文の構成}
\noindent
2 章では基礎知識について述べる。\\
3 章では関連研究について述べる。\\
4 章では提案手法について述べる。\\
5 章では実験内容について述べる。\\
6 章では実験結果に関する評価および考察について述べる。\\
7 章では本論文のまとめについて述べる。\\

% ==================================================




    
\section{データについて}
本研究では以下のデータセットを用いる。
\begin{enumerate}
    \item Walmart Sales%
    \footnote{\url{https://www.kaggle.com/datasets/mikhail1681/walmart-sales}}

    \item Restaurant Sales report%
    \footnote{\url{https://www.kaggle.com/datasets/rajatsurana979/fast-food-sales-report}}
    
    \item Sales of a Supermarket%
    \footnote{\url{https://www.kaggle.com/datasets/lovishbansal123/sales-of-a-supermarket}}
    
    \item {Store Sales Time Series Forecasting%
    \footnote{\url{https://www.kaggle.com/competitions/store-sales-time-series-forecasting}}}

\end{enumerate}


% ==================================================
\chapter{基礎知識}
\section{LightGBM}
LightGBM（Light Gradient Boosting Machine）は、Microsoft Researchによって開発された勾配ブースティング手法に基づく機械学習アルゴリズムである。決定木を基礎モデルとして多数組み合わせることで、高い表現力を持つ予測モデルを構築する点に特徴がある。

まず、本研究で用いるLightGBMは決定木ベースのアルゴリズムであるため、決定木の概要について簡単に述べる。決定木は、入力される特徴量に対して、特定の特徴量があるしきい値以上かどうかなどの条件に基づいてデータを順に分割していき、最終的に葉ノードと呼ばれる末端のノードごとに予測値（回帰問題であれば数値、分類問題であればクラス）が割り当てられるモデルである。根ノードから葉ノードまでの分岐は、人間が理解しやすいif--thenルールの列として表現できるため、予測結果の解釈が比較的容易である。また、特徴量のスケーリングを必要とせず、非線形な関係や特徴量同士の相互作用も表現しやすいという利点がある。

LightGBMは、この決定木を多数逐次的に学習し、それぞれが前のモデルの誤差を補正するように重ね合わせることで、最終的な予測性能を高める勾配ブースティング決定木の一実装である。その中でも、特に高速な学習とメモリ効率の良さ、大規模データセットへの適用のしやすさを重視して設計されている。


\section{Early Stopping}

勾配ブースティングやニューラルネットワークなどの反復学習型アルゴリズムにおいては、
学習回数を増やしすぎると訓練データに過度に適合し、
未知データに対する汎化性能が低下する過学習が生じることがある。
この問題に対処する手法の一つがEarly Stoppingである。

Early Stoppingでは、訓練データとは別に検証データを用意し、
各イテレーションにおける検証データに対する評価指標を監視する。
検証誤差が一定回数分のイテレーションにわたって改善しなくなった時点で
学習を終了し、その時点までで最も性能の良かったモデルを採用する。
これにより、以下のような利点が得られる。

\begin{itemize}
  \item 過学習が始まる前のタイミングで学習を停止できるため、汎化性能の低下を抑制できる
  \item 学習回数を自動的に調整できるため、不要なイテレーションを避け、計算時間を削減できる
  \item ハイパーパラメーターとして学習回数を過度に大きく設定しても、
        Early Stoppingによって実際の有効な学習回数が自動的に制御される
\end{itemize}



\section{Time Cross Validation}

時系列データを対象とする予測モデルの評価では、データの時系列順序を保存したまま
訓練データと検証データを分割する必要がある。
一般的な$k$-foldクロスバリデーションでは、データの時系列を考慮せずに任意に分割するため、
将来のデータが過去より先に学習過程へ取り込まれてしまい、情報漏洩が生じる可能性がある。
この問題は時系列予測において重大であり、モデルが過大評価される原因となる。

この問題を避けるために用いられる手法が
Time Cross Validation（時系列クロスバリデーション）である。
Time Cross Validationでは、時系列順序を維持したまま、
過去から未来へ向かう形で訓練期間と検証期間を複数設定し、
それぞれの分割に対してモデルを学習および評価する（図\ref{drow}）。

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{drow.png}
\caption{Time Cross Validationの分割例}
\label{drow}
\end{figure}

Time Cross Validationの一般的な分割方法は以下のとおりである。

\begin{itemize}
  \item 分割1：過去のデータを訓練、直後の一定期間を検証に使用する
  \item 分割2：訓練期間を前方へ広げ、次の期間を検証に使用する
  \item 分割1と分割2を複数回繰り返し、各分割の評価指標の平均を最終的なモデル指標とする
\end{itemize}


\section{平均絶対誤差（MAE）}

回帰タスクにおけるモデルの性能評価には、さまざまな指標が用いられる。
本研究では、予測値と実測値のずれを評価する指標として
平均絶対誤差（Mean Absolute Error、MAE）を採用する。

観測値を$y_i$、モデルによる予測値を$\hat{y}_i$、
サンプル数を$N$とすると、MAEは式(2.1)で定義される。

\begin{equation}
  MAE = \frac{1}{N} \sum_{i=1}^{N} \left| y_i - \hat{y}_i \right|
\end{equation}

MAEは各サンプルにおける誤差の絶対値を平均したものであり、
以下のような特徴をもつ。

\begin{itemize}
  \item 誤差の単位が目的変数と同じであるため、解釈が直感的である
  \item 二乗誤差を用いる指標（MSE、RMSE）に比べて外れ値の影響を受けにくい
  \item 正負の誤差が打ち消し合うことがないため、全体としてのずれの大きさを素直に反映する
\end{itemize}

POSデータにおける売上金額や販売数量の予測では、
「平均してどれくらい外しているか」をそのままの単位で把握できることが重要である。
そのため、本研究では、売上や数量のような非負の連続値を対象とする
予測タスクに適した指標としてMAEを採用し、各手法の性能比較に用いる。


\chapter{関連研究}
\section{LightGBMを用いたファインチューニングによる予測モデル}

Yeら\cite{ye2023_pv_finetune}は、太陽光発電プラントにおける出力予測を対象として、
LightGBMとXGBoostを組み合わせた事前学習・ファインチューニング型の予測モデルを提案している。
具体的には、まず複数プラントから得られた気象データを用いて大規模な学習データセットを構成し、
LightGBMおよびXGBoostによるハイブリッドモデルを事前学習する。
その後、新たな発電所や環境条件に対応するために、各プラント固有のデータに対して
ファインチューニングを行うことで、出力予測精度と汎化性能の向上を図っている。
実験の結果、提案モデルは従来手法と比較して、
複数地点を同時に予測する設定においても一貫して低い誤差を達成することが報告されている\cite{ye2023_pv_finetune}。

このように、勾配ブースティング系モデルに対して事前学習とファインチューニングの枠組みを導入することで、
新たに得られたデータや別環境のデータに適応させる手法が提案されている。
一方で、本研究が対象とするのは太陽光発電ではなくPOSデータであり、
新規データが逐次到着する状況を前提とするのではなく、
既存の履歴データに対して追加学習を施すことでモデルの予測精度を高める点に特徴がある。
さらに、本研究ではLightGBM単独のモデルをベースとし、
カテゴリカルカラムによるデータ分割とカテゴリ別ファインチューニングを組み合わせることで、
カテゴリごとの局所的な挙動を補正する手法を検討している。
すなわち、Yeらの研究が
「新しいプラントや条件への適応」を主な目的としているのに対し、
本研究は「既存データを用いたモデル再学習による精度向上」に焦点を当てている点で
問題設定およびアプローチが異なる。

% ========================================================================================
\chapter{提案手法}
\section{提案手法の内容}
本研究では、LightGBMによって学習したベースモデルに対し、カテゴリカルカラムごとにファインチューニングを行うことで予測精度を向上させる手法を提案する。手順を以下に示す。

\begin{enumerate}
  \item ベースモデルの学習

  全データを用いてLightGBMのモデルを学習し、全体的な傾向を捉えたベースモデルを構築する。

  \item データのカテゴリ別分割

  カテゴリカルカラムを1つ選択する。選択したカテゴリカルカラムの値ごとにデータを分割し、カテゴリごとの部分データセットを作成する。

  \item ベースモデルの重みを初期値とした追加学習

  各カテゴリのデータセットに対して、ベースモデルの重みを初期値として読み込み、当該カテゴリに属するデータのみで追加学習を行う。この追加学習により、ベースモデルが保持する全体傾向を維持したまま、カテゴリ特有の挙動をモデルに反映させることができる。

  \item 推論時のモデル選択

  推論時には、入力データが属するカテゴリに対応するファインチューニング済みモデルを選択し、そのモデルを用いて予測値を算出する。
\end{enumerate}


データセットにカテゴリカルカラムcol\_catが存在し、A、Bのどちらかの値であるときの提案手法の例を示す(図\ref{model-ex})。

\begin{figure}[H]
\centering 
\includegraphics[scale=0.5]{model-ex.png}
\caption{提案手法の処理を表すフロー}
\label{model-ex}
\end{figure}

\section{提案手法の位置づけ}

本研究の提案手法は、LightGBMによる基本的なモデル学習を行った後に、
カテゴリカルカラムごとのファインチューニングを行うことで、
予測精度を向上させることを目的とするものである。
本手法が位置付けられる領域は、初期モデル学習後の精度改善手法であり、
以下に示す既存手法と同じ段階に属する。

\begin{itemize}
  \item クロスバリデーションによる汎化性能の向上
  \item ハイパーパラメータチューニング
  \item 同系アンサンブル（seedや\texttt{learning\_rate}のわずかな変更）
  \item 異種アンサンブル（LightGBMとXGBoostの組み合わせなど）
  \item 目的変数の変換（\texttt{log1p}など）
  \item 残差モデル（モデルの残差を別モデルで学習する手法）
\end{itemize}

これらの手法はいずれも、基本モデルを構築した後に、
その性能を追加的に向上させるための手法である。
本研究の提案手法も同様に、ベースモデルが捉える大域的な傾向を保持しつつ、
カテゴリ単位の局所的な挙動を補正する点に特徴をもつ。
したがって、本手法はLightGBMを用いた予測タスクにおける
仕上げの精度改善手法として位置付けられる。
本研究では時系列版のクロスバリデーションを比較対象とする。

% ================================================================
\chapter{実験内容}
\section{使用するデータセット}

本研究では、LightGBMを用いた予測タスクの汎用性を確認するため、
構造や規模の異なる4種類の公開データセットを用いる。
いずれも売上または販売数量を目的変数とする時系列データである。

\subsection{Walmart Sales Dataset}

Walmartにおける週次売上データであり、各店舗・各部門の売上推移を扱う。
本研究では、以下の主要特徴量を使用する。

\begin{itemize}
  \item Store：店舗IDを表すカテゴリカル変数
  \item Date：週次データの日付
  \item Weekly\_Sales：該当週の売上金額（目的変数）
  \item Holiday\_Flag：祝日週か否かを示すフラグ
  \item Temperature：その週の平均気温
  \item Fuel\_Price：燃料価格
  \item CPI：消費者物価指数
  \item Unemployment：失業率
\end{itemize}

これらの特徴量は、天候・価格・経済指標などが売上に影響を与える点を捉えるために適している。

\subsection{Restaurant Sales Report}

ローカルレストランにおける日次販売記録であり、以下のカテゴリカル変数と
数値変数を含む。

\begin{itemize}
  \item Date：日付
  \item Item\_Name：商品名を表すカテゴリカル変数
  \item Item\_Type：食品または飲料などの商品カテゴリ
  \item Item\_Price：商品の単価
  \item Quantity：販売数量（目的変数）
  \item Transaction\_Type：現金・オンラインなどの支払い方法
  \item Received\_By：担当したスタッフの性別
  \item Time\_of\_Sale：販売時間帯（Morning、Afternoon など）
\end{itemize}

複数のカテゴリカル特徴量を含むため、LightGBMのカテゴリカル処理性能が評価しやすいデータセットである。

\subsection{Sales of a Supermarket}

スーパーマーケットの販売記録であり、個々の取引情報を含む。
使用する主な特徴量は以下のとおりである。

\begin{itemize}
  \item Branch：店舗（A、B、C）の識別子
  \item Customer\_Type：会員・非会員などの顧客タイプ
  \item Gender：顧客の性別
  \item Product\_Line：商品カテゴリ
  \item Unit\_Price：商品の単価
  \item Quantity：販売数量（目的変数）
  \item Date：購入日
  \item Time：購入時刻
  \item Payment：支払い方法
  \item Rating：顧客満足度を表す 1〜10 のスコア
\end{itemize}

カテゴリ属性と数値属性の両方を多く含む点が特徴である。

\subsection{Store Sales Time Series Forecasting}

Ecuador の大手スーパーマーケットチェーンにおける大規模販売データであり、
店舗・商品ファミリー別の日次販売数を扱う。

\begin{itemize}
  \item Date：日付
  \item Store\_Nbr：店舗番号
  \item Family：製品ファミリー（カテゴリカル変数）
  \item Sales：販売数量（目的変数）
  \item OnPromotion：プロモーション対象商品数
\end{itemize}





数百万件規模のデータであるため、LightGBMの高速学習性能を評価できる。
\section{実験手順}

本研究では、各データセットに対してLightGBMを用いた3種類の手法でモデルを構築し、
予測性能を比較する。比較対象には、単一モデルによる学習結果を用いるベースラインと、
時系列構造を考慮したTime Cross Validationを採用する。また、提案手法における
ファインチューニングの影響を適切に評価するため、学習には
Early Stoppingを導入する。

\begin{enumerate}
  \item \textbf{ベースライン（単一LightGBMモデル）}

  \quad 各データセット全体を訓練データとして用いてLightGBMを学習する。
  学習にEarly Stoppingを適用し、
  検証データに対する誤差が改善しなくなるまで学習を継続する。
  これにより、モデルが過学習を避けつつ最適な学習回数で収束するよう調整する。
  ベースラインは、Time Cross Validationおよび提案手法の比較基準として用いる。

  \item \textbf{Time Cross Validation}

  \quad 時系列の順序を保持したまま複数の訓練期間と評価期間を設定し、
  各分割ごとにLightGBMを学習する。
  この際にもEarly Stoppingを適用し、
  分割ごとの最適な学習回数でモデルを構築する。
  各分割の誤差の平均値を評価指標として用いる。
  Time Cross Validationは時系列予測における標準的な評価方法であり、
  本研究における重要な比較対象である。

  \item \textbf{提案手法（カテゴリ別ファインチューニング）}

  \quad まず、全データを用いてLightGBMのベースモデルを構築する。
  この際、ベースラインと同様にEarly Stoppingを用い、
  検証データで精度が向上しなくなるまで学習を行う。
  これは、ファインチューニングによる学習回数の単純な増加が
  精度向上の主因とならないようにするためである。

  次に、データセットに含まれるカテゴリカルカラムのうち、
  種類数が最も多いカラムを1つ選択し、その値ごとにデータセットを分割する。
  各カテゴリのデータに対して、ベースモデルの重みを初期値として読み込み、
  当該カテゴリのデータのみを用いて追加学習を行う。
  この追加学習により、ベースモデルが捉える大域的傾向を保持したまま、
  カテゴリごとの局所的挙動を反映させることができる。

  さらに、提案手法の安定性を検証するため、
  目的変数と無関係に乱数で生成したカテゴリカルカラム
  （A、B、Cの3値をランダムに付与したもの）を1列だけ追加した条件でも実験を行う。
  この際、元の特徴量および目的変数には一切変更を加えない。
  ランダムカラムをカテゴリ分割の基準として用いてファインチューニングを行い、
  MAEの変化を観察する。
  これは、無意味なカテゴリに対して過適合することなく、
  ベースモデルが保持する大域的傾向が精度を損なわないことを確認するためである。

  推論時には、入力サンプルが属するカテゴリに対応した
  ファインチューニング済みモデルを選択し、予測値を算出する。
\end{enumerate}
各データセットにおいて、検証データの期間は以下のように設定をする。
\begin{table}[H]
\centering
\caption{各データセットにおける検証データ期間}
\label{val-periods}
\begin{tabular}{lcc}
\hline
\textbf{Dataset} & \textbf{検証開始日} & \textbf{検証終了日} \\
\hline
Beverage Sales & 2023-11-01 & 2023-11-30 \\
Restaurant Sales Report & 2023-10-01 & 2023-10-30 \\
Sales of a Supermarket & 2019-02-01 & 2019-02-28 \\
Walmart Sales Dataset & 2012-09-01 & 2012-09-30 \\
\hline
\end{tabular}
\end{table}

\section{LightGBMのパラメーター}

本研究で用いるLightGBMのパラメーターは以下である。

\begin{itemize}
  \item 決定木の最大本数：\texttt{n\_estimators = 5000}
  \item 木の最大深さ：\texttt{max\_depth = 20}
  \item 学習率：\texttt{learning\_rate = 0.01}
  \item 分割の最小利得：\texttt{min\_split\_gain = 0.1}
  \item 目的関数：\texttt{objective = "regression"}（回帰タスク）
\end{itemize}

\section{Time Cross Validationにおけるデータの分割方法}
まず表\ref{val-periods}に示した検証期間を固定し、その期間より前の全データを訓練データ候補とする。すなわち、検証期間は常に時系列の末尾側に配置され、訓練データはその直前までの履歴データのみから構成される。

訓練データ候補に対しては、日付を表す列（\texttt{date}）を用いて昇順にソートしたうえで、Time Cross Validationの各分割を構成する。ここで、全訓練サンプル数を$N$とし、$k$番目の分割（$k=1,\dots,10$）における訓練データサイズ$N_k$を、式\ref{eq:tcv_split}のように定める。

\begin{equation}
  N_k = \left\lceil \frac{k}{10} N \right\rceil
  \label{eq:tcv_split}
\end{equation}

訓練データのうち先頭から$N_k$件を用いてモデルを学習し、表\ref{val-periods}で定めた検証期間のデータを検証データとして評価する。$k$を1から10まで変化させることで、全訓練期間の$1/10,2/10,\dots,10/10$を順に用いるTime Cross Validationとなる。

\section{評価指標}
各手法で得られたMAEを比較することで、提案手法が
既存手法と比べてどの程度精度向上に寄与するかを定量的に評価する。

% ================================================================

\chapter{評価と考察}
\section{実験結果}
各データセットに対するそれぞれの手法のMAEを示す（表\ref{mae-main}）。
\begin{table}[H]
\centering
\caption{各データセットにおける手法ごとのMAEの比較}
\label{mae-main}
\begin{tabular}{llll}
\hline
データセット & ベースライン & 提案手法 & Time Cross Validation\\
\hline
Walmart Sales Dataset & 66480.5938 & 52892.0512 & 82751.7063 \\
Restaurant Sales Report & 1.4848 & 1.4249 & 1.4971 \\
Sales of a Supermarket & 2.6108 & 2.5982 & 2.6312 \\
Store Sales Time Series Forecasting & 123.9055 & 121.5178 & 157.9872 \\
\hline
\end{tabular}
\end{table}
全てのデータセットにおいて、提案手法の MAE は、ベースライン、Time Cross Validation の MAE より小さくなっている。


次に、ランダムカラム追加時の実験を行う。
変更率を式\ref{eq:change_rate}で定義し、表\ref{mae-random-change}に示す。

\begin{equation}
  \label{eq:change_rate}
  \resizebox{\linewidth}{!}{$
    \text{変更率} =
    \frac{\text{ランダムカラム選択時のMAE} - \text{提案手法のMAE}}{\text{提案手法のMAE}} \times 100
  $}
\end{equation}

\begin{table}[H]
\centering
\caption{提案手法に対するランダムカラム追加時の MAE と変更率}
\label{mae-random-change}
\begin{tabular}{llll}
\hline
データセット & 提案手法 & ランダムなカラム & 変更率（\%） \\

\hline
Walmart Sales Dataset & 52892.0512 & 52910.4478 & +0.0348 \\
Restaurant Sales Report & 1.4249 & 1.4261 & +0.0843 \\
Sales of a Supermarket & 2.5982 & 2.6001 & +0.0732 \\
Store Sales Time Series Forecasting & 121.5178 & 121.5534 & +0.0294 \\
\hline
\end{tabular}
\end{table}
MAE の変更率は最大でも+0.0843\%に収まっている。
%============================================
\section{考察}
\subsection{精度の改善について}
表\ref{mae-main}より、4 つのデータセットすべてにおいて、
提案手法の MAE はベースラインおよび Time Cross Validationよりも小さい値を示した。
これは、LightGBM によって学習されたベースモデルが POSデータに共通する
大域的傾向を捉えたうえで、カテゴリ別ファインチューニングにより
カテゴリ固有の挙動を補正できたことを意味している。

POSデータでは、店舗や商品カテゴリごとに売上の水準や変動幅が大きく異なる。
ベースラインでは、全体のデータを1つのモデルで学習するため、
データ数の多い店舗や商品カテゴリに引きずられやすく、
一部のカテゴリに対してはバイアスの大きい予測となる可能性がある。
これに対して提案手法では、ベースモデルで大域的な季節性やトレンドを学習したあと、
カテゴリごとのデータのみを用いて追加学習を行うことで、
各カテゴリに固有の水準や変動パターンを反映できる。
その結果として、特にカテゴリ間の差異が大きい
Walmart Sales DatasetやStore Sales Time Series Forecastingにおいて、
ベースラインと比べて顕著なMAEの改善が見られたと解釈できる。

また、Time Cross Validationは時系列の順序を保った評価方法であり、
汎化性能を厳密に測るうえで有用である一方で、
各分割で利用可能な訓練データが限定されるという性質をもつ。
したがって、十分なデータ量を用いて学習できるベースラインや提案手法と比べると、
モデルが学習できる情報量が少なく、MAEが大きくなる傾向が表れた。

さらに、表\ref{mae-random-change}に示したように、
目的変数と無関係なランダムカラムを追加し、
そのカラムに基づいてカテゴリ別ファインチューニングを行った場合でも、
MAEの変更率は最大で+0.0843\%と0.1\%未満に収まっている。
この結果から、提案手法の精度向上は、
単にモデルの学習回数が増加したことや、
任意のカテゴリでデータを分割したことに起因するものではなく、
実際に意味のあるカテゴリ（店舗や商品ファミリーなど）で
データを分割したことによる効果である。
言い換えると、提案手法は無関係なカテゴリ情報に対して過度に適合せず、
POSデータに内在する有用な構造を利用した場合にのみ、
安定して精度向上をもたらす手法である。

以上より、提案手法が精度向上を達成した主な要因は、
\begin{enumerate}
    \item ベースモデルによる大域的傾向の獲得
    \item カテゴリ別ファインチューニングによる局所的挙動の補正
\end{enumerate}
の二つがうまく分担している点にある。
この二段階構成により、POSデータのように
「全体としては共通のパターンをもちつつ、カテゴリごとに挙動が異なる」
という構造をもつデータに対して、有効に機能する手法であると結論づける。

% ===================================

\subsection{カテゴリカルカラムの選択方法について}
本研究では、単に種類数が最も多いカラムを機械的に選択した。しかし、扱うデータセットによっては他のカラムを選択した方がよい場合も存在する。以下に、選択基準となりうる要素を述べる。
\begin{enumerate}
    \item 種類数が多いカラムを選択した方がよい。ただし、多すぎるカラムは選ぶべきではない。例えば、ID に相当するカラムを選択すると、1 つのデータのみでファインチューニングを行うことになり、精度の改善は望めない。
    \item データセットを分割した際に、各分割間で分布や傾向が十分に異なるようなカラムを選択することが望ましい。例えば、「性別、学年、身長」からなる小学生のデータセットが存在し、身長を目的変数とするタスクを考える。このとき、カテゴリカルカラムとして性別と学年のいずれを用いることもできるが、学年ごとにデータを分割した方が、各学年で身長の水準や分布が大きく異なるため、より明確に傾向の異なる分割を得ることができる。
\end{enumerate}


\chapter{おわりに}
本研究では、LightGBMによるベースモデル学習に対して、
カテゴリ別ファインチューニングを組み合わせた精度向上手法を提案し、
複数の公開データセットを用いてその有効性を検証した。
実験の結果、提案手法はベースラインおよび
Time Cross Validationと比較して一貫して
低いMAEを示し、予測精度を向上させることが確認できた。
また、無関係なランダムカテゴリを追加した条件でも精度が大きく崩れず、
手法の安定性が示された。
本研究で得られた結果は、POSデータのように
カテゴリごとに異なるパターンを含む時系列データに対して、
ベースモデルと追加学習を組み合わせるアプローチが有効であることを示した。

%===============================================================
\chapter*{謝辞}
本研究を進めるにあたり、松澤智史准教授には終始ご指導と温かい励ましをいただきました。深く感謝申し上げます。また、電気電子情報工学科の鈴木海友助教には、研究の進め方や技術的な助言を賜り、心より御礼申し上げます。さらに、松澤研究室の皆様には、日々の議論や助言を通して本研究に多くの示唆をいただきました。この場を借りて厚く感謝いたします。

\newpage
\renewcommand{\bibname}{参考文献}
\bibliographystyle{jplain} 
\bibliography{refs}     


\end{document}